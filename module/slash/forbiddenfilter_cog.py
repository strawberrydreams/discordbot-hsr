from __future__ import annotations
import discord
import json
import pathlib
import re
import logging
import unicodedata
from typing import List, Optional
from discord.ext import commands

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
DATA_FILE = pathlib.Path(__file__).parents[2] / "settings" / "forbidden_words.json"

# ì˜µì…˜: ìëª¨ ì…ë ¥(ã… ã…” ã„´ ...)ì„ ì™„ì„±í˜•ìœ¼ë¡œ ê²°í•©í• ì§€
COMBINE_JAMO = True

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
ZERO_WIDTH = {
    "\u200b",  # ZWSP
    "\u200c",  # ZWNJ
    "\u200d",  # ZWJ
    "\u2060",  # Word Joiner
    "\ufeff",  # BOM
}

def _strip_zero_width(s: str) -> str:
    return "".join(ch for ch in s if ch not in ZERO_WIDTH)

def _strip_separators_symbols(s: str) -> str:
    """
    ê³µë°±/êµ¬ë‘ì /ê¸°í˜¸/ì œì–´ë¬¸ì ì œê±° -> ê¸€ì/ìˆ«ìë§Œ ë‚¨ê¹€.
    """
    out = []
    for ch in s:
        cat = unicodedata.category(ch)  # 'L*' ê¸€ì, 'N*' ìˆ«ì, 'P*' êµ¬ë‘ì , 'S*' ê¸°í˜¸, 'Z*' êµ¬ë¶„ì...
        if cat.startswith("L") or cat.startswith("N"):
            out.append(ch)
    return "".join(out)

def _strip_to_core_chars(s: str) -> str:
    """
    ê³µê²©ì ì¸ ì •ê·œí™”: í•œê¸€ ì™„ì„±í˜•(ê°€-í£)ê³¼ ì˜ë¬¸(a-z)ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°.
    ìˆ«ì, ìëª¨, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ëª¨ë‘ ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ì—¬ ì œê±°í•¨.
    ì˜ˆ: 'ì•„1ë‹ˆ' -> 'ì•„ë‹ˆ', 'ì•„ã…‘ë‹ˆ' -> 'ì•„ë‹ˆ'
    """
    # ê°€-í£: \uac00-\ud7a3
    # a-z: \u0061-\u007a
    return re.sub(r"[^ê°€-í£a-z]", "", s)

def _normalize_term(s: str) -> str:
    """
    ê¸ˆì§€ì–´(ì •ìƒ í‘œê¸°) ì •ê·œí™”: ì „ê°/ì¡°í•© í†µí•© + ì†Œë¬¸ì
    * ê¸ˆì§€ì–´ JSONì—ëŠ” í‰ë²”í•œ í‘œê¸°ë¥¼ ë„£ëŠ” ê±¸ ê¶Œì¥.
    """
    return unicodedata.normalize("NFKC", s).lower()

def _normalize_message_for_match(s: str) -> str:
    """
    ë©”ì‹œì§€ ì •ê·œí™”: ì „ê°/ì¡°í•© í†µí•© -> ì†Œë¬¸ì -> ì œë¡œí­ ì œê±° -> êµ¬ë¶„ì/ê¸°í˜¸ ì œê±° -> (ì˜µì…˜) NFC ê²°í•©
    """
    s = unicodedata.normalize("NFKC", s).lower()
    s = _strip_zero_width(s)
    s = _strip_separators_symbols(s)
    if COMBINE_JAMO:
        s = unicodedata.normalize("NFC", s)
    return s

def _build_pattern(terms: List[str]) -> re.Pattern:
    """
    ì •ê·œí™”ëœ ê¸ˆì§€ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ OR íŒ¨í„´ìœ¼ë¡œ ì»´íŒŒì¼ (ë¶€ë¶„ì¼ì¹˜)
    """
    if not terms:
        return re.compile(r"^\b$")  # ì•„ë¬´ê²ƒë„ ë§¤ì¹˜ë˜ì§€ ì•ŠëŠ” ë”ë¯¸
    escaped = [re.escape(t) for t in terms if t]
    return re.compile("|".join(escaped))

class ForbiddenFilterCog(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self._banned: List[str] = []
        self._banned_pattern: Optional[re.Pattern] = None
        self.load_prohibited_words()

    def _read_words(self) -> List[str]:
        if not DATA_FILE.exists():
            logging.warning("âš ï¸ %s íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.", DATA_FILE.name)
            return []
        try:
            with DATA_FILE.open(encoding="utf-8") as fp:
                data = json.load(fp)
            if not isinstance(data, list):
                raise ValueError("JSON ìµœìƒë‹¨ì€ ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            # JSONì˜ ê° í•­ëª©ì„ ì •ê·œí™”í•˜ì—¬ ì €ì¥
            return [_normalize_term(str(w)) for w in data if str(w).strip()]
        except Exception as e:
            logging.error("âŒ %s ë¡œë“œ ì‹¤íŒ¨: %s", DATA_FILE.name, e)
            return []

    def load_prohibited_words(self) -> List[str]:
        """JSONì„ ì½ì–´ ë‚´ë¶€ ìºì‹œì— ì €ì¥í•˜ê³  íŒ¨í„´ì„ ê°±ì‹ í•©ë‹ˆë‹¤."""
        self._banned = self._read_words()
        self._banned_pattern = _build_pattern(self._banned)
        logging.info("ğŸ“¥ ê¸ˆì§€ì–´ %dê°œ ë¡œë“œ", len(self._banned))
        return self._banned

    @commands.Cog.listener()
    async def on_message(self, message: discord.Message):
        if message.author.bot or not self._banned or self._banned_pattern is None:
            return

        # ë©”ì‹œì§€ ì •ê·œí™” (ê³µë°±/êµ¬ë‘ì /ê¸°í˜¸/ì œë¡œí­ ì œê±° í¬í•¨)
        text_norm = _normalize_message_for_match(message.content)

        # 1ì°¨ ê²€ì‚¬: ê¸°ë³¸ ì •ê·œí™” (ê³µë°±/êµ¬ë‘ì  ì œê±°, ìˆ«ì/ìëª¨ ìœ ì§€) -> "18", "ã…‹ã…‹ã…‹" ë“±ì„ ì¡ìŒ
        text_norm = _normalize_message_for_match(message.content)
        match = self._banned_pattern.search(text_norm)
        
        # 2ì°¨ ê²€ì‚¬: ê³µê²©ì  ì •ê·œí™” (ìˆ«ì/ìëª¨ ì œê±°) -> "ì•„1ë‹ˆ", "ì•„ã…‘ë‹ˆ" ë“±ì„ ì¡ìŒ
        # 1ì°¨ì—ì„œ ê±¸ë¦¬ì§€ ì•Šì•˜ì„ ë•Œë§Œ ìˆ˜í–‰ (ì¤‘ë³µ ì ë°œ ë°©ì§€)
        if not match:
            text_aggressive = _strip_to_core_chars(text_norm)
            match = self._banned_pattern.search(text_aggressive)

        if match:
            bad_word = match.group()  # ì •ê·œí™”ëœ ê¸ˆì§€ì–´
            await message.channel.send(
                f"ğŸ›‘ğŸ›‘ {message.author.mention} ì‚ì‚‘~~ ë‚˜ìœ ë‹¨ì–´ **{bad_word}** ê¸ˆì§€! ê¸ˆì§€! ğŸ›‘ğŸ›‘"
            )
            
            # Increment forbidden count
            attendance_cog = self.bot.get_cog("AttendanceCog")
            if attendance_cog:
                attendance_cog.increment_forbidden_count(message.author.id)

async def setup(bot: commands.Bot):
    await bot.add_cog(ForbiddenFilterCog(bot))